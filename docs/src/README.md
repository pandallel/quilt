**Quilt** is a local-first, modular memory and context engine. It watches your work, fragments your documents into meaningful pieces (swatches), embeds them into a searchable memory (the swatch book), and assembles contextual spreads in response to queries.

Use Quilt to power LLM tools with fast, structured, and evolving contextâ€”without relying on cloud infrastructure or leaking your knowledge.

---

## âœ¨ Core Principles

- **Local-first** â€“ Everything runs on your machine. No cloud, no leaks.
- **Modular** â€“ Watching, swatching, embedding, and querying are decoupled and swappable.
- **Quiet** â€“ You donâ€™t interact with Quilt directlyâ€”it works behind the scenes to support other systems.
- **Crafted** â€“ Inspired by the precision, care, and reuse of quilting.

---

## ğŸ§  Domain Concepts

| Term            | Description                                                                                 |
| --------------- | ------------------------------------------------------------------------------------------- |
| **Material**    | A raw document or fileâ€”notes, code, transcripts, etc.                                       |
| **Swatch**      | A meaningful fragment cut from a Material                                                   |
| **Swatch Book** | The searchable memory of embedded Swatches                                                  |
| **Spread**      | A contextual bundle of Swatches and their source Material, assembled in response to a Query |

---

## ğŸ§° What Quilt Does

- ğŸ“‚ Watches one or more folders for new or updated Materials
- âœ‚ï¸ Cuts Materials into Swatches based on content structure
- ğŸ”¢ Embeds Swatches using a local model (e.g. `llama.cpp`, `gguf`)
- ğŸ“š Stores them in a fast, local Swatch Book
- ğŸ§  Responds to Queries by assembling contextual Spreads
